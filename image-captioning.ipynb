{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7680955,"sourceType":"datasetVersion","datasetId":4481237}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers\n!pip install torch","metadata":{"execution":{"iopub.status.busy":"2024-02-22T20:05:06.812574Z","iopub.execute_input":"2024-02-22T20:05:06.813336Z","iopub.status.idle":"2024-02-22T20:05:32.427738Z","shell.execute_reply.started":"2024-02-22T20:05:06.813300Z","shell.execute_reply":"2024-02-22T20:05:32.426766Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.37.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2023.12.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Using Image Path**","metadata":{}},{"cell_type":"code","source":"from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\nimport torch\nfrom PIL import Image\n\nmodel = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\nfeature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\ntokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n\n\nmax_length = 16\nnum_beams = 4\ngen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}\ndef predict_step(image_paths):\n  images = []\n  for image_path in image_paths:\n    i_image = Image.open(image_path)\n    if i_image.mode != \"RGB\":\n      i_image = i_image.convert(mode=\"RGB\")\n\n    images.append(i_image)\n\n  pixel_values = feature_extractor(images=images, return_tensors=\"pt\").pixel_values\n  pixel_values = pixel_values.to(device)\n\n  output_ids = model.generate(pixel_values, **gen_kwargs)\n\n  preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n  preds = [pred.strip() for pred in preds]\n  return preds\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T20:06:34.338423Z","iopub.execute_input":"2024-02-22T20:06:34.339122Z","iopub.status.idle":"2024-02-22T20:06:41.138184Z","shell.execute_reply.started":"2024-02-22T20:06:34.339086Z","shell.execute_reply":"2024-02-22T20:06:41.137326Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"predict_step(['/kaggle/input/images/img.jpg'])","metadata":{"execution":{"iopub.status.busy":"2024-02-22T20:08:31.893970Z","iopub.execute_input":"2024-02-22T20:08:31.894363Z","iopub.status.idle":"2024-02-22T20:08:33.326227Z","shell.execute_reply.started":"2024-02-22T20:08:31.894337Z","shell.execute_reply":"2024-02-22T20:08:33.325113Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\nYou may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['a cat standing on a floor next to a person']"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Using Image Link**","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\nimage_to_text = pipeline(\"image-to-text\", model=\"nlpconnect/vit-gpt2-image-captioning\")\n\nimage_to_text(\"https://images.livemint.com/img/2022/08/01/1600x900/Cat-andriyko-podilnyk-RCfi7vgJjUY-unsplash_1659328989095_1659328998370_1659328998370.jpg\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T20:10:21.822645Z","iopub.execute_input":"2024-02-22T20:10:21.823317Z","iopub.status.idle":"2024-02-22T20:10:30.700403Z","shell.execute_reply.started":"2024-02-22T20:10:21.823281Z","shell.execute_reply":"2024-02-22T20:10:30.699652Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': 'a small kitten sitting in the grass '}]"},"metadata":{}}]}]}